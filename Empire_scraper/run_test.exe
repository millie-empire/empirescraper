#!/bin/bash  

#Start up
if [ ${1:-false} == "setupdev" ]
then
    #start message
    echo "Installing required packages"

    #finds the location of requirements.txt
    array=(`find $PWD -name requirements.txt`)
    limit=1
    for i in "${array[@]}"
    #finds the final path of the requirements.txt
    do :
    	if [ "${#array[@]}" -eq "${limit}" ]; then
        	#when at the last value (correct location
        	#of the client_secret.json) and
        	#stores path of the file
        	dir=$i
        	#gets the directory of the requirements.txt
        	parent_path="$(dirname "$dir")"
    	fi
    	let "limit++"
    done
    #got to the directory with requirements.txt
    cd $parent_path

    #installs the required packages
    pip install -r requirements.txt
fi


cd

#finds the path of the file with the API credentials
array=(`find $PWD -name client_secret.json`)
limit=1
for i in "${array[@]}"
#finds the final path of the file with the API credentials
do :
   if [ "${#array[@]}" -eq "${limit}" ]; then
    #when at the last value (correct location
    #of the client_secret.json) and
    #stores path of the file
       file_path=$i
   fi
   let "limit++"
done

#creates an environment variable to point to API creds file
echo "this is the path of the json file"
echo $file_path
export GOOGLE_API_CREDENTIALS=$file_path  



cd
    #finds the location of the spider to crawl the webpages
    array=(`find $PWD -name thisisalocationfile.txt`)
    limit=1
    for i in "${array[@]}"
    do :
       if [ "${#array[@]}" -eq "${limit}" ]; then
        #when at the last value (correct location
        #of the thisisalocationfile.txt) and
        #stores path of the file
           dir=$i
           test_path="$(dirname "$dir")"
       fi
       let "limit++"
    done

    #got to the directory with test.py
    cd $test_path
    echo "THIS THE SCRAPY PATH"
    pwd

    #runs the scraper code
    scrapy crawl empire

echo "DONE"